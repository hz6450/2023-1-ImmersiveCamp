{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdccdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no faces!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 113\u001b[0m\n\u001b[0;32m    111\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m, ori)\n\u001b[0;32m    112\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacial landmarks\u001b[39m\u001b[38;5;124m'\u001b[39m, img)\n\u001b[1;32m--> 113\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mresult\u001b[49m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    115\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "scaler = 0.3\n",
    "\n",
    "# initialize face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(0)\n",
    "# load overlay image\n",
    "overlay = cv2.imread('samples/ryan_transparent.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# overlay function\n",
    "def overlay_transparent(background_img, img_to_overlay_t, x, y, overlay_size=None):\n",
    "    bg_img = background_img.copy()\n",
    "    # convert 3 channels to 4 channels\n",
    "    if bg_img.shape[2] == 3:\n",
    "        bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    if overlay_size is not None:\n",
    "        img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "\n",
    "    b, g, r, a = cv2.split(img_to_overlay_t)\n",
    "\n",
    "    mask = cv2.medianBlur(a, 5)\n",
    "\n",
    "    h, w, _ = img_to_overlay_t.shape\n",
    "    roi = bg_img[int(y - h / 2):int(y + h / 2), int(x - w / 2):int(x + w / 2)]\n",
    "\n",
    "    img1_bg = cv2.bitwise_and(roi.copy(), roi.copy(), mask=cv2.bitwise_not(mask))\n",
    "    img2_fg = cv2.bitwise_and(img_to_overlay_t, img_to_overlay_t, mask=mask)\n",
    "\n",
    "    bg_img[int(y - h / 2):int(y + h / 2), int(x - w / 2):int(x + w / 2)] = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "    # convert 4 channels to 4 channels\n",
    "    bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    return bg_img\n",
    "\n",
    "face_roi = []\n",
    "face_sizes = []\n",
    "\n",
    "# loop\n",
    "while True:\n",
    "    # read frame buffer from video\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # resize frame\n",
    "    img = cv2.resize(img, (int(img.shape[1] * scaler), int(img.shape[0] * scaler)))\n",
    "    ori = img.copy()\n",
    "\n",
    "    # find faces\n",
    "    if len(face_roi) == 0:\n",
    "        faces = detector(img, 1)\n",
    "    else:\n",
    "        roi_img = img[face_roi[0]:face_roi[1], face_roi[2]:face_roi[3]]\n",
    "        # cv2.imshow('roi', roi_img)\n",
    "        faces = detector(roi_img)\n",
    "\n",
    "    # no faces\n",
    "    if len(faces) == 0:\n",
    "        print('no faces!')\n",
    "\n",
    "    # find facial landmarks\n",
    "    for face in faces:\n",
    "        if len(face_roi) == 0:\n",
    "            dlib_shape = predictor(img, face)\n",
    "            shape_2d = np.array([[p.x, p.y] for p in dlib_shape.parts()])\n",
    "        else:\n",
    "            dlib_shape = predictor(roi_img, face)\n",
    "            shape_2d = np.array(\n",
    "                [[p.x + face_roi[2], p.y + face_roi[0]] for p in dlib_shape.parts()])\n",
    "\n",
    "        for s in shape_2d:\n",
    "            cv2.circle(img, center=tuple(s), radius=1, color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # compute face center\n",
    "        center_x, center_y = np.mean(shape_2d, axis=0).astype(np.int)\n",
    "\n",
    "        # compute face boundaries\n",
    "        min_coords = np.min(shape_2d, axis=0)\n",
    "        max_coords = np.max(shape_2d, axis=0)\n",
    "\n",
    "        # draw min, max coords\n",
    "        cv2.circle(img, center=tuple(min_coords), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "        cv2.circle(img, center=tuple(max_coords), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # compute face size\n",
    "        face_size = max(max_coords - min_coords)\n",
    "        face_sizes.append(face_size)\n",
    "        if len(face_sizes) > 10:\n",
    "            del face_sizes[0]\n",
    "        mean_face_size = int(np.mean(face_sizes) * 1.8)\n",
    "\n",
    "        # compute face roi\n",
    "        face_roi = np.array([int(min_coords[1] - face_size / 2), int(max_coords[1] + face_size / 2),\n",
    "                             int(min_coords[0] - face_size / 2), int(max_coords[0] + face_size / 2)])\n",
    "        face_roi = np.clip(face_roi, 0, 10000)\n",
    "\n",
    "        # draw overlay on face\n",
    "        result = overlay_transparent(ori, overlay, center_x + 8, center_y - 25,\n",
    "                                     overlay_size=(mean_face_size, mean_face_size))\n",
    "\n",
    "    # visualize\n",
    "    cv2.imshow('original', ori)\n",
    "    cv2.imshow('facial landmarks', img)\n",
    "    cv2.imshow('result', result)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f603f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
